{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Paula\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as gl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"src/results\"\n",
    "\n",
    "\"\"\" datetime = \"/2011-03-24_15\"\n",
    "df = pd.read_csv(path + datetime + '.csv')  \"\"\"\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in gl.glob(path + '/20*.csv'):\n",
    "    dfs.append(pd.read_csv(file))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "#df.count() #cada csv tiene 160920 filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = df.iloc[:, 8].values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "modelo = LabelEncoder().fit_transform(modelo) #codificación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cap', 'dist', 'origen_id', 'dest_id', 'len_origen_tag', 'len_dest_tag',\n",
       "       'criterion', 'degree', 'total_balance', 'abs_flux', 'h',\n",
       "       'Beam Irradiance (W/m2)', 'Diffuse Irradiance (W/m2)',\n",
       "       'Ambient Temperature (C)', 'Plane of Array Irradiance (W/m2)',\n",
       "       'Cell Temperature (C)', 'modelo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[8], axis=1) #se elimina la antigua con los strings del modelo\n",
    "df['modelo'] = modelo #se añade la nueva codificada al final\n",
    "\n",
    "X = df.iloc[:, 1:] \n",
    "X = X.drop(['datetime', 'timestamp', 'load', 'DC Array Output (W)' , 'Pavg', 'dif'], axis=1)\n",
    "y = df.iloc[:, 0].values #valores de overflow\n",
    "\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler() #escalado de datos\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC #ESTO HA TARDADO LA VIDA Y MEDIA....\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94436   249]\n",
      " [ 1461   406]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.982289336316182"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.model_selection import cross_val_score\\n\\naccuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10) #se añade el clasificador o modelo, cv = K\\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100)) '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.model_selection import GridSearchCV\\nfrom sklearn.neural_network import MLPClassifier\\n\\nparameters = {\\n    \\'hidden_layer_sizes\\': [(5,5,1), (6,6,1), (7,7,1), (8,8,1)],\\n    \\'activation\\': [\\'logistic\\', \\'tanh\\',\\'relu\\'],\\n    \\'solver\\': [\\'lbfgs\\', \\'sgd\\',\\'adam\\'],\\n    #\\'batch_size\\': [25, 50, 75, 100],\\n    #\\'epochs\\': [10, 20, 30],\\n    \\'learning_rate\\': [\\'constant\\',\\'adaptive\\'],\\n}\\n\\ngrid_search = GridSearchCV(MLPClassifier(max_iter=100), parameters, n_jobs=-1, cv=10, scoring = \\'accuracy\\')\\ngrid_search.fit(X_train, y_train)\\n\\nbest_accuracy = grid_search.best_score_\\nbest_parameters = grid_search.best_params_\\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\\nprint(\"Best Parameters:\", best_parameters)\\n\\n\\n########\\nBest Accuracy: 98.20 %\\nBest Parameters: {\\'activation\\': \\'tanh\\', \\'hidden_layer_sizes\\': (7, 7, 1), \\'learning_rate\\': \\'constant\\', \\'solver\\': \\'adam\\'} '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
